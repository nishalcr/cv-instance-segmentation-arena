{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9876831,"sourceType":"datasetVersion","datasetId":6063726}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Setup and Import Libraries:","metadata":{}},{"cell_type":"code","source":"!pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"execution":{"iopub.status.busy":"2024-11-11T23:02:00.896023Z","iopub.execute_input":"2024-11-11T23:02:00.896411Z","iopub.status.idle":"2024-11-11T23:04:13.559493Z","shell.execute_reply.started":"2024-11-11T23:02:00.896382Z","shell.execute_reply":"2024-11-11T23:04:13.558432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import libraries\nimport os\nimport cv2\nimport torch\nfrom torch.cuda.amp import autocast, GradScaler\nfrom detectron2.engine import DefaultTrainer, DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2 import model_zoo\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.visualizer import Visualizer\nimport logging","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"detectron2\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Register COCO Datasets (Training, Validation, Test):","metadata":{}},{"cell_type":"code","source":"# Register COCO dataset (Train and Validation)\nregister_coco_instances(\"coco_train\", {}, \"/kaggle/input/mscoco/annotations_trainval2017/annotations/instances_train2017.json\", \"/kaggle/input/mscoco/train2017/train2017\")\nregister_coco_instances(\"coco_val\", {}, \"/kaggle/input/mscoco/annotations_trainval2017/annotations/instances_val2017.json\", \"/kaggle/input/mscoco/val2017/val2017\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Configuration Setup:","metadata":{}},{"cell_type":"code","source":"cfg = get_cfg()\n\n# Load the Cascade Mask R-CNN configuration from the model zoo\ncfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"))\n\n# --- Configuration for dataset ---\ncfg.DATASETS.TRAIN = (\"coco_train\",)  # Specify the training dataset\ncfg.DATASETS.TEST = (\"coco_val\",)    # Specify the validation dataset\n\n# --- DataLoader settings ---\ncfg.DATALOADER.NUM_WORKERS = 4  # Number of workers to load the data in parallel\n\n# --- Input settings ---\ncfg.INPUT.MIN_SIZE_TRAIN = (800,)  # Minimum size of images during training\ncfg.INPUT.MAX_SIZE_TRAIN = 1333  # Maximum size of images during training\n\n# --- Model weights ---\n# cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/cascade_mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\" # Load pretrained weights from model zoo\n\n# --- Solver settings ---\ncfg.SOLVER.IMS_PER_BATCH = 8  # Batch size during training\ncfg.SOLVER.BASE_LR = 0.00025  # Learning rate for the optimizer\ncfg.SOLVER.MAX_ITER = 50000  # Total number of iterations for training\n\n# --- ROI Head settings ---\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  # Number of proposals per image during training\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 80  # COCO dataset has 80 object classes\n\n# --- Output directory ---\ncfg.OUTPUT_DIR = \"/kaggle/working/output\"  # Directory to save model checkpoints, logs, and other outputs\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlogger.info(f\"Using device: {device}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Train the Model:","metadata":{}},{"cell_type":"code","source":"# Initialize the trainer\ntrainer = DefaultTrainer(cfg)\ntrainer.model.to(device)  # Move model to GPU\n\n# Mixed precision setup\nscaler = GradScaler()\n\n# Log training start\nlogger.info(\"Training started...\")\n\n# Training loop with mixed precision\ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Testing the Model:","metadata":{}},{"cell_type":"code","source":"# # Testing the model after training and logging evaluation results\n# eval_results = trainer.test(cfg, trainer.model)\n# logger.info(\"Evaluation Results: %s\", eval_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Sample Inference on a Single Image:","metadata":{}},{"cell_type":"code","source":"# # Set up the predictor for inference\n# predictor = DefaultPredictor(cfg)\n\n# # Load a sample image for inference (replace with actual test image path)\n# img = cv2.imread(\"/kaggle/input/mscoco/test2017/sample_image.jpg\")\n\n# # Run inference on the image\n# outputs = predictor(img)\n\n# # Visualize the predictions on the image\n# v = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"coco_train\"), scale=1.2)\n# out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n# # Save or display the output image\n# output_image_path = \"/kaggle/working/output/inference_result.jpg\"\n# cv2.imwrite(output_image_path, out.get_image()[:, :, ::-1])\n# logger.info(f\"Inference result saved at {output_image_path}\")","metadata":{},"execution_count":null,"outputs":[]}]}