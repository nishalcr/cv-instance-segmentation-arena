{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "Import required libraries including PyTorch, torchvision, and other dependencies. Set up CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Print the device being used\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Dataset\n",
    "Load the dataset, create data loaders, and implement data augmentation techniques. Convert annotations to the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images and masks\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        # Convert the mask to a numpy array\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[1:]  # Remove background\n",
    "\n",
    "        # Split the color-encoded mask into a set of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # Get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # Convert everything to a torch tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)  # All objects are labeled as 1\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "# Define transformations for data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = CustomDataset('path/to/dataset', get_transform(train=True))\n",
    "dataset_test = CustomDataset('path/to/dataset', get_transform(train=False))\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# Define data loaders\n",
    "data_loader = DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "    collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "data_loader_test = DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Model Parameters\n",
    "Set up configuration for Cascade Mask R-CNN including backbone architecture, learning rates, anchor sizes, and other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Model Parameters\n",
    "\n",
    "# Define the model configuration\n",
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "\n",
    "# Replace the box predictor with a new one for our dataset\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Replace the mask predictor with a new one for our dataset\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Define training parameters\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Print model configuration\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Cascade Mask R-CNN Model\n",
    "Initialize the Cascade Mask R-CNN model with the configured parameters. Set up multiple detection heads for cascade architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Cascade Mask R-CNN Model\n",
    "\n",
    "# Import necessary libraries for Cascade Mask R-CNN\n",
    "from torchvision.models.detection import CascadeRCNN\n",
    "\n",
    "# Initialize the Cascade Mask R-CNN model\n",
    "model = CascadeRCNN(\n",
    "    backbone=torchvision.models.resnet50(pretrained=True),\n",
    "    num_classes=num_classes,\n",
    "    rpn_anchor_generator=model.rpn.anchor_generator,\n",
    "    box_roi_pool=model.roi_heads.box_roi_pool,\n",
    "    mask_roi_pool=model.roi_heads.mask_roi_pool,\n",
    "    box_head=model.roi_heads.box_head,\n",
    "    mask_head=model.roi_heads.mask_head,\n",
    "    box_predictor=model.roi_heads.box_predictor,\n",
    "    mask_predictor=model.roi_heads.mask_predictor,\n",
    ")\n",
    "\n",
    "# Set up multiple detection heads for cascade architecture\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.cascade_rcnn.CascadeRCNNPredictor(\n",
    "    in_channels=in_features,\n",
    "    num_classes=num_classes,\n",
    "    num_stages=3,  # Number of stages in the cascade\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Print the model to verify the architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "Implement training loop with learning rate scheduling, loss computation, and model checkpointing. Monitor training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Pipeline\n",
    "\n",
    "# Define the training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        # Compute total loss\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training metrics\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(data_loader)}], Loss: {losses.item():.4f}\")\n",
    "        i += 1\n",
    "\n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader_test:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            # Compute total loss\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Print validation metrics\n",
    "            print(f\"Validation Loss: {losses.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Evaluate model performance using metrics like mAP, precision, recall on validation set. Generate performance reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Import necessary libraries for evaluation\n",
    "from torchvision.ops import box_iou\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Function to calculate mean Average Precision (mAP)\n",
    "def calculate_map(pred_boxes, pred_labels, pred_scores, true_boxes, true_labels, iou_threshold=0.5):\n",
    "    all_ap = []\n",
    "    for label in set(true_labels):\n",
    "        true_label_mask = true_labels == label\n",
    "        pred_label_mask = pred_labels == label\n",
    "\n",
    "        true_boxes_label = true_boxes[true_label_mask]\n",
    "        pred_boxes_label = pred_boxes[pred_label_mask]\n",
    "        pred_scores_label = pred_scores[pred_label_mask]\n",
    "\n",
    "        if len(pred_boxes_label) == 0:\n",
    "            continue\n",
    "\n",
    "        ious = box_iou(pred_boxes_label, true_boxes_label)\n",
    "        max_iou, max_iou_idx = ious.max(dim=1)\n",
    "\n",
    "        tp = (max_iou >= iou_threshold).sum().item()\n",
    "        fp = (max_iou < iou_threshold).sum().item()\n",
    "        fn = len(true_boxes_label) - tp\n",
    "\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        all_ap.append(f1)\n",
    "\n",
    "    return sum(all_ap) / len(all_ap) if len(all_ap) > 0 else 0\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "model.eval()\n",
    "all_pred_boxes = []\n",
    "all_pred_labels = []\n",
    "all_pred_scores = []\n",
    "all_true_boxes = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in data_loader_test:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        for output, target in zip(outputs, targets):\n",
    "            all_pred_boxes.append(output['boxes'].cpu())\n",
    "            all_pred_labels.append(output['labels'].cpu())\n",
    "            all_pred_scores.append(output['scores'].cpu())\n",
    "            all_true_boxes.append(target['boxes'].cpu())\n",
    "            all_true_labels.append(target['labels'].cpu())\n",
    "\n",
    "# Concatenate all predictions and ground truths\n",
    "all_pred_boxes = torch.cat(all_pred_boxes)\n",
    "all_pred_labels = torch.cat(all_pred_labels)\n",
    "all_pred_scores = torch.cat(all_pred_scores)\n",
    "all_true_boxes = torch.cat(all_true_boxes)\n",
    "all_true_labels = torch.cat(all_true_labels)\n",
    "\n",
    "# Calculate mAP\n",
    "map_score = calculate_map(all_pred_boxes, all_pred_labels, all_pred_scores, all_true_boxes, all_true_labels)\n",
    "print(f\"mAP: {map_score:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Generate performance report\n",
    "performance_report = {\n",
    "    \"mAP\": map_score,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-score\": f1\n",
    "}\n",
    "\n",
    "print(\"Performance Report:\", performance_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Visualization\n",
    "Run inference on test images, visualize detection results, and create visualization utilities for masks and bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference and Visualization\n",
    "\n",
    "# Import necessary libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Function to visualize bounding boxes and masks\n",
    "def visualize_predictions(image, boxes, masks, labels, scores, threshold=0.5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for box, mask, label, score in zip(boxes, masks, labels, scores):\n",
    "        if score < threshold:\n",
    "            continue\n",
    "\n",
    "        # Draw bounding box\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Draw mask\n",
    "        mask = mask.cpu().numpy()\n",
    "        mask = mask > 0.5\n",
    "        image[mask] = image[mask] * 0.5 + torch.tensor([1, 0, 0], dtype=torch.float32).to(device) * 0.5\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Run inference on test images and visualize results\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in random.sample(list(data_loader_test), 5):  # Visualize 5 random test images\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        for image, output in zip(images, outputs):\n",
    "            visualize_predictions(image, output['boxes'], output['masks'], output['labels'], output['scores'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
